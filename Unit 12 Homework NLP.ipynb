{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 12 - Tales from the Crypto\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sentiment Analysis\n",
    "\n",
    "Use the [newsapi](https://newsapi.org/) to pull the latest news articles for Bitcoin and Ethereum and create a DataFrame of sentiment scores for each coin.\n",
    "\n",
    "Use descriptive statistics to answer the following questions:\n",
    "1. Which coin had the highest mean positive score?\n",
    "2. Which coin had the highest negative score?\n",
    "3. Which coin had the highest positive score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\tarks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk as nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from newsapi import NewsApiClient\n",
    "from dotenv import find_dotenv, get_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Reading the News API key enviroment variable\n",
    "#news_api_key = get_key(find_dotenv(), \"NEWS_API_KEY\")\n",
    "news_api_key = \"f681efdf495c4638bb6c4031a5a1cdaa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f681efdf495c4638bb6c4031a5a1cdaa\n"
     ]
    }
   ],
   "source": [
    "print(news_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your api key environment variable\n",
    "newsapi = NewsApiClient(api_key=news_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a news api client\n",
    "from newsapi import NewsApiClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the Bitcoin news articles\n",
    "bitcoin_headlines = newsapi.get_everything(q=\"bitcoin\", language=\"en\", sort_by=\"relevancy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the Ethereum news articles\n",
    "ethereum_headlines = newsapi.get_everything(q=\"ethereum\", language=\"en\", sort_by=\"relevancy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bitcoin sentiment scores DataFrame\n",
    "bitcoin_sentiments = []\n",
    "\n",
    "for article in bitcoin_headlines[\"articles\"]: #for each article\n",
    "    text = article[\"content\"] #pull out the content and assign it to a variable\n",
    "    date = article[\"publishedAt\"][:10] #pull out the timestamp and assign it to a variable\n",
    "    sentiment = analyzer.polarity_scores(text) #calculate scores (save it to a variable)\n",
    "    compound = sentiment[\"compound\"] #save compound score\n",
    "    pos = sentiment[\"pos\"] #save positive score\n",
    "    neu = sentiment[\"neu\"] #save neutral score\n",
    "    neg = sentiment[\"neg\"] #save negative score\n",
    "\n",
    "    bitcoin_sentiments.append({\n",
    "        \"text\": text,\n",
    "        \"date\": date,\n",
    "        \"compound\": compound,\n",
    "        \"positive\": pos,\n",
    "        \"negative\": neg,\n",
    "        \"neutral\": neu\n",
    "\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create bitcoin dataframe\n",
    "bitcoin_df = pd.DataFrame(bitcoin_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "cols = [\"compound\", \"negative\", \"positive\", \"neutral\", \"text\"]\n",
    "bitcoin_df = bitcoin_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.929</td>\n",
       "      <td>Just weeks after Tesla started accepting Bitco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2960</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.942</td>\n",
       "      <td>Shares of Square are up more than 6% today aft...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>Tesla’s relationship with bitcoin is not a dal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.829</td>\n",
       "      <td>Cryptocurrency continues to gain mainstream ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4939</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.816</td>\n",
       "      <td>Image: Tesla\\r\\n\\n \\n\\n Tesla has stopped acce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   compound  negative  positive  neutral  \\\n",
       "0    0.3818      0.00     0.071    0.929   \n",
       "1    0.2960      0.00     0.058    0.942   \n",
       "2    0.0000      0.00     0.000    1.000   \n",
       "3    0.7506      0.00     0.171    0.829   \n",
       "4    0.4939      0.05     0.134    0.816   \n",
       "\n",
       "                                                text  \n",
       "0  Just weeks after Tesla started accepting Bitco...  \n",
       "1  Shares of Square are up more than 6% today aft...  \n",
       "2  Tesla’s relationship with bitcoin is not a dal...  \n",
       "3  Cryptocurrency continues to gain mainstream ac...  \n",
       "4  Image: Tesla\\r\\n\\n \\n\\n Tesla has stopped acce...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Ethereum sentiment scores DataFrame\n",
    "ethereum_sentiments = []\n",
    "\n",
    "for article in ethereum_headlines[\"articles\"]: #for each article\n",
    "    text = article[\"content\"] #pull out the content and assign it to a variable\n",
    "    date = article[\"publishedAt\"][:10] #pull out the timestamp and assign it to a variable\n",
    "    sentiment = analyzer.polarity_scores(text) #calculate scores (save it to a variable)\n",
    "    compound = sentiment[\"compound\"] #save compound score\n",
    "    pos = sentiment[\"pos\"] #save positive score\n",
    "    neu = sentiment[\"neu\"] #save neutral score\n",
    "    neg = sentiment[\"neg\"] #save negative score\n",
    "\n",
    "    ethereum_sentiments.append({\n",
    "        \"text\": text,\n",
    "        \"date\": date,\n",
    "        \"compound\": compound,\n",
    "        \"positive\": pos,\n",
    "        \"negative\": neg,\n",
    "        \"neutral\": neu\n",
    "\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ethereum dataframe\n",
    "ethereum_df = pd.DataFrame(ethereum_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "cols = [\"compound\", \"negative\", \"positive\", \"neutral\", \"text\"]\n",
    "ethereum_df = ethereum_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2263</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.940</td>\n",
       "      <td>Vitalik Buterin, the creator of Ethereum, on W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.4019</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.778</td>\n",
       "      <td>Their investors call them disruptive innovator...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.7506</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.829</td>\n",
       "      <td>Cryptocurrency continues to gain mainstream ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.966</td>\n",
       "      <td>Venmo is jumping aboard the cryptocurrency ban...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4019</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.917</td>\n",
       "      <td>Solana isn’t known yet outside of the crypto c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   compound  negative  positive  neutral  \\\n",
       "0    0.2263      0.00     0.060    0.940   \n",
       "1   -0.4019      0.15     0.072    0.778   \n",
       "2    0.7506      0.00     0.171    0.829   \n",
       "3    0.0258      0.00     0.034    0.966   \n",
       "4    0.4019      0.00     0.083    0.917   \n",
       "\n",
       "                                                text  \n",
       "0  Vitalik Buterin, the creator of Ethereum, on W...  \n",
       "1  Their investors call them disruptive innovator...  \n",
       "2  Cryptocurrency continues to gain mainstream ac...  \n",
       "3  Venmo is jumping aboard the cryptocurrency ban...  \n",
       "4  Solana isn’t known yet outside of the crypto c...  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ethereum_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.355315</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.095300</td>\n",
       "      <td>0.887350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.297612</td>\n",
       "      <td>0.027793</td>\n",
       "      <td>0.076896</td>\n",
       "      <td>0.087942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.736000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.019350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.821000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.342950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.869500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.624625</td>\n",
       "      <td>0.050250</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>0.974500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.845500</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.217000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        compound   negative   positive    neutral\n",
       "count  20.000000  20.000000  20.000000  20.000000\n",
       "mean    0.355315   0.017500   0.095300   0.887350\n",
       "std     0.297612   0.027793   0.076896   0.087942\n",
       "min     0.000000   0.000000   0.000000   0.736000\n",
       "25%     0.019350   0.000000   0.025500   0.821000\n",
       "50%     0.342950   0.000000   0.071000   0.869500\n",
       "75%     0.624625   0.050250   0.168000   0.974500\n",
       "max     0.845500   0.071000   0.217000   1.000000"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the Bitcoin Sentiment\n",
    "bitcoin_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.128900</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.046800</td>\n",
       "      <td>0.942000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.304466</td>\n",
       "      <td>0.036611</td>\n",
       "      <td>0.059529</td>\n",
       "      <td>0.070125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.401900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.778000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.917750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.012900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>0.958000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.254725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.817600</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        compound   negative   positive    neutral\n",
       "count  20.000000  20.000000  20.000000  20.000000\n",
       "mean    0.128900   0.011200   0.046800   0.942000\n",
       "std     0.304466   0.036611   0.059529   0.070125\n",
       "min    -0.401900   0.000000   0.000000   0.778000\n",
       "25%     0.000000   0.000000   0.000000   0.917750\n",
       "50%     0.012900   0.000000   0.036000   0.958000\n",
       "75%     0.254725   0.000000   0.074500   1.000000\n",
       "max     0.817600   0.150000   0.210000   1.000000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe the Ethereum Sentiment\n",
    "ethereum_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions:\n",
    "\n",
    "Q: Which coin had the highest mean positive score?\n",
    "\n",
    "A: Bitcoin had the highest mean positive score\n",
    "\n",
    "Q: Which coin had the highest compound score?\n",
    "\n",
    "A: Ethereum had the highest compound score.\n",
    "\n",
    "Q. Which coin had the highest positive score?\n",
    "\n",
    "A: Bitcoin had the highest positive score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Natural Language Processing\n",
    "---\n",
    "###   Tokenizer\n",
    "\n",
    "In this section, you will use NLTK and Python to tokenize the text for each coin. Be sure to:\n",
    "1. Lowercase each word.\n",
    "2. Remove Punctuation.\n",
    "3. Remove Stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from string import punctuation\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tarks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     C:\\Users\\tarks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to download corpora\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('reuters')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['articles']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(\"articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(\"articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the tokenizer function\n",
    "def tokenizer(text):\n",
    "    \"\"\"Tokenizes text.\"\"\"\n",
    "    sw = set(my_stopwords.words('english')) #1) defining stopwords\n",
    "    words = word_tokenize # Create a tokenized list of the words\n",
    "    # Lemmatize words into root words\n",
    "    lem = lemmatizer.lemmatize('tokenizer') # Lemmatize words into root words\n",
    "    output = [word.lower() for word in lem if word.lower() not in my_stopwords] # Remove the stop words\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for Bitcoin\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new tokens column for Ethereum\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGrams and Frequency Analysis\n",
    "\n",
    "In this section you will look at the ngrams and word frequency for each coin. \n",
    "\n",
    "1. Use NLTK to produce the n-grams for N = 2. \n",
    "2. List the top 10 words for each coin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the counter function\n",
    "def word_counter(bitcoin_df): \n",
    "    # Combine all articles in corpus into one large string\n",
    "    big_string = ' '.join(newsapi)\n",
    "    processed = process_text(big_string)\n",
    "    top_10 = dict(Counter(processed).most_common(10))\n",
    "    return pd.bitcoin_df(list(top_10.items()), columns=['word', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def bigram_counter(bitcoin_df): \n",
    "    # Combine all articles in corpus into one large string\n",
    "    big_string = ' '.join(newsapi)\n",
    "    processed = process_text(big_string)\n",
    "    bigrams = ngrams(processed, n=2)\n",
    "    top_10 = dict(Counter(bigrams).most_common(10))\n",
    "    return pd.bitcoin_df(list(top_10.items()), columns=['bigram', 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get word counts\n",
    "word_counts = Counter(bitcoin_df)\n",
    "#print(dict(word_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'compound': 1, 'negative': 1, 'positive': 1, 'neutral': 1, 'text': 1}\n"
     ]
    }
   ],
   "source": [
    "# get top x words\n",
    "print(dict(word_counts.most_common(20)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Bitcoin N-grams where N=2\n",
    "bigram_counts = Counter(ngrams(bitcoin_df, n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Ethereum N-grams where N=2\n",
    "bigram_counts = Counter(ngrams(ethereum_df, n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function token_count generates the top 10 words for a given coin\n",
    "def token_count(tokens, N=3):\n",
    "    \"\"\"Returns the top N tokens from the frequency count\"\"\"\n",
    "    return Counter(tokens).most_common(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use token_count to get the top 10 words for Bitcoinz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data\n",
    "# Getting the corpus (first 1000 articles from Reuters dataset)\n",
    "all_docs_id = reuters.fileids()\n",
    "corpus_id = all_docs_id[0:1000]\n",
    "corpus = [reuters.raw(doc) for doc in corpus_id]\n",
    "\n",
    "# Initializing TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "#Fitting the vectorizer to actually find the TF-IDFs\n",
    "X_corpus = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve words list from corpus to put in dataframe\n",
    "words_corpus = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-137-e8fdcb68070c>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-137-e8fdcb68070c>\"\u001b[1;36m, line \u001b[1;32m9\u001b[0m\n\u001b[1;33m    (by=[\"TF-IDF\"], ascending=False)\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Getting the TF-IDF weight of each word in corpus as DataFrame\n",
    "words_corpus_df = pd.DataFrame(\n",
    "    list(zip(words_corpus, \n",
    "             np.ravel(X_corpus.mean(axis=0)))), \n",
    "    columns=[\"Word\", \"TF-IDF\"]\n",
    ")\n",
    "\n",
    "bitcoin_df = words_corpus_df.sort_values\n",
    "(by=[\"TF-IDF\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>articles</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>status</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>totalresults</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Frequency\n",
       "0      articles        1.0\n",
       "1        status        1.0\n",
       "2  totalresults        1.0"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use token_count to get the top 10 words for Ethereum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data\n",
    "# Getting the corpus (first 1000 articles from Reuters dataset)\n",
    "all_docs_id = reuters.fileids()\n",
    "corpus_id = all_docs_id[0:1000]\n",
    "corpus = [reuters.raw(doc) for doc in corpus_id]\n",
    "\n",
    "# Initializing TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "#Fitting the vectorizer to actually find the TF-IDFs\n",
    "X_corpus = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve words list from corpus to put in dataframe\n",
    "words_corpus = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the TF-IDF weight of each word in corpus as DataFrame\n",
    "words_corpus_df = pd.DataFrame(\n",
    "    list(zip(words_corpus, \n",
    "             np.ravel(X_corpus.mean(axis=0)))), \n",
    "    columns=[\"Word\", \"TF-IDF\"]\n",
    ")\n",
    "\n",
    "bitcoin_df = words_corpus_df.sort_values\n",
    "(by=[\"TF-IDF\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethereum_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Clouds\n",
    "\n",
    "In this section, you will generate word clouds for each coin to summarize the news for each coin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.figsize'] = [20.0, 10.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "mpl.rcParams[\"figure.figsize\"] = [20.0, 10.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating TF-IDF for the working corpus.\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(bitcoin_headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame Representation of the TF-IDF results\n",
    "bitcoin_df = pd.DataFrame(\n",
    "    list(zip(vectorizer.get_feature_names(), np.ravel(X.sum(axis=0)))),\n",
    "    columns=[\"Word\", \"Frequency\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order the DataFrame by word frequency in descending order\n",
    "bitcoin_df = bitcoin_df.sort_values(by=[\"Frequency\"], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>articles</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>status</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>totalresults</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Frequency\n",
       "0      articles        1.0\n",
       "1        status        1.0\n",
       "2  totalresults        1.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the Bitcoin word cloud\n",
    "# Top words will be those with a frequency between 10 ans 30 (thumb rule)\n",
    "top_words = bitcoin_df[\n",
    "    (bitcoin_df[\"Frequency\"] >= 10) & (bitcoin_df[\"Frequency\"] <= 30)\n",
    "]\n",
    "\n",
    "bitcoin_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud().generate(input_text)\n",
    "plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame Representation of the TF-IDF results\n",
    "ethereum_df = pd.DataFrame(\n",
    "    list(zip(vectorizer.get_feature_names(), np.ravel(X.sum(axis=0)))),\n",
    "    columns=[\"Word\", \"Frequency\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>articles</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>status</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>totalresults</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Frequency\n",
       "0      articles        1.0\n",
       "1        status        1.0\n",
       "2  totalresults        1.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the Ethereum word cloud\n",
    "# Top words will be those with a frequency between 10 ans 30 (thumb rule)\n",
    "top_words = ethereum_df[\n",
    "    (ethereum_df[\"Frequency\"] >= 10) & (ethereum_df[\"Frequency\"] <= 30)\n",
    "]\n",
    "ethereum_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = WordCloud().generate(input_text)\n",
    "plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Named Entity Recognition\n",
    "\n",
    "In this section, you will build a named entity recognition model for both Bitcoin and Ethereum, then visualize the tags using SpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the language model for SpaCy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Bitcoin NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all of the Bitcoin text together\n",
    "concat_df = pd.concat([bitcoin_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Argument 'string' has incorrect type (expected str, got DataFrame)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-8c80d7a3f03e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Set article to be analyzed with spaCy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconcat_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[0;32m    981\u001b[0m         \u001b[0mDOCS\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;31m#call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m         \"\"\"\n\u001b[1;32m--> 983\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcomponent_cfg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[0mcomponent_cfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m   1063\u001b[0m                 \u001b[0mErrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mE088\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1064\u001b[0m             )\n\u001b[1;32m-> 1065\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m     def update(\n",
      "\u001b[1;31mTypeError\u001b[0m: Argument 'string' has incorrect type (expected str, got DataFrame)"
     ]
    }
   ],
   "source": [
    "# Set article to be analyzed with spaCy\n",
    "doc = nlp(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-01a0cb418ce0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run the NER processor on all of the text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdisplacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ent'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Add a title to the document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# YOUR CODE HERE!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the NER processor on all of the text\n",
    "displacy.render(doc, style='ent')\n",
    "\n",
    "# Add a title to the document\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the visualization\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Entities\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethereum NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all of the Ethereum text together\n",
    "concat_df = pd.concat([ethereum_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-128-01a0cb418ce0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run the NER processor on all of the text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdisplacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ent'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Add a title to the document\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# YOUR CODE HERE!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "# Run the NER processor on all of the text\n",
    "displacy.render(doc, style='ent')\n",
    "\n",
    "# Add a title to the document\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Render the visualization\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all Entities\n",
    "# YOUR CODE HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
